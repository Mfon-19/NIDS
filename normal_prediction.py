import pandas as pd
import numpy as np
import joblib 
import os

# --- Configuration ---

# 1. Path to the CSV file generated by CICFlowMeter from your captured traffic
new_data_csv = r"C:\Users\mfone\Desktop\Programs\NIDS\network_normal_flow.csv"

# 2. Path to the directory where you saved your trained files
model_files_dir = "trained_model_files"
model_path = os.path.join(model_files_dir, "random_forest_model.joblib")
scaler_path = os.path.join(model_files_dir, "scaler.joblib")
encoder_path = os.path.join(model_files_dir, "label_encoder.joblib")

# --- Load New Data ---
print(f"Loading new data from: {new_data_csv}")
try:
    new_df = pd.read_csv(new_data_csv)
    new_df.columns = new_df.columns.str.strip()
    new_df.replace([np.inf, -np.inf], np.nan, inplace=True)
    print(f"Loaded {len(new_df)} flows.")
except FileNotFoundError:
    print(f"Error: CSV file not found at {new_data_csv}")
    exit()
except Exception as e:
    print(f"Error reading CSV: {e}")
    exit()

# --- Load Model and Preprocessors ---
print("Loading trained model, scaler, and label encoder...")
try:
    model = joblib.load(model_path)
    scaler = joblib.load(scaler_path)
    label_encoder = joblib.load(encoder_path)
except FileNotFoundError:
    print(f"Error: Model/Scaler/Encoder file not found in {model_files_dir}. Ensure they were saved correctly.")
    exit()
except Exception as e:
    print(f"Error loading model files: {e}")
    exit()

# --- Preprocessing (Using Loaded Objects & Renaming) ---
print("Preprocessing new data...")

column_mapping = {
    'ACK Flag Cnt': 'ACK Flag Count',
    'Active Max': 'Active Max',
    'Active Mean': 'Active Mean',
    'Active Min': 'Active Min',
    'Active Std': 'Active Std',
    'Bwd Blk Rate Avg': 'Bwd Avg Bulk Rate',
    'Bwd Byts/b Avg': 'Bwd Avg Bytes/Bulk',
    'Bwd Header Len': 'Bwd Header Length',
    'Bwd IAT Max': 'Bwd IAT Max',
    'Bwd IAT Mean': 'Bwd IAT Mean',
    'Bwd IAT Min': 'Bwd IAT Min',
    'Bwd IAT Std': 'Bwd IAT Std',
    'Bwd IAT Tot': 'Bwd IAT Total',
    'Bwd PSH Flags': 'Bwd PSH Flags',
    'Bwd Pkt Len Max': 'Bwd Packet Length Max',
    'Bwd Pkt Len Mean': 'Bwd Packet Length Mean',
    'Bwd Pkt Len Min': 'Bwd Packet Length Min',
    'Bwd Pkt Len Std': 'Bwd Packet Length Std',
    'Bwd Pkts/b Avg': 'Bwd Avg Packets/Bulk',
    'Bwd Pkts/s': 'Bwd Packets/s',
    'Bwd Seg Size Avg': 'Avg Bwd Segment Size',
    'Bwd URG Flags': 'Bwd URG Flags',
    'CWE Flag Count': 'CWE Flag Count',
    'Down/Up Ratio': 'Down/Up Ratio',
    'Dst Port': 'Destination Port',
    'ECE Flag Cnt': 'ECE Flag Count',
    'FIN Flag Cnt': 'FIN Flag Count',
    'Flow Byts/s': 'Flow Bytes/s',
    'Flow Duration': 'Flow Duration',
    'Flow IAT Max': 'Flow IAT Max',
    'Flow IAT Mean': 'Flow IAT Mean',
    'Flow IAT Min': 'Flow IAT Min',
    'Flow IAT Std': 'Flow IAT Std',
    'Flow Pkts/s': 'Flow Packets/s',
    'Fwd Act Data Pkts': 'act_data_pkt_fwd',
    'Fwd Blk Rate Avg': 'Fwd Avg Bulk Rate',
    'Fwd Byts/b Avg': 'Fwd Avg Bytes/Bulk',
    'Fwd Header Len': 'Fwd Header Length', 
    'Fwd IAT Max': 'Fwd IAT Max',
    'Fwd IAT Mean': 'Fwd IAT Mean',
    'Fwd IAT Min': 'Fwd IAT Min',
    'Fwd IAT Std': 'Fwd IAT Std',
    'Fwd IAT Tot': 'Fwd IAT Total',
    'Fwd PSH Flags': 'Fwd PSH Flags',
    'Fwd Pkt Len Max': 'Fwd Packet Length Max',
    'Fwd Pkt Len Mean': 'Fwd Packet Length Mean',
    'Fwd Pkt Len Min': 'Fwd Packet Length Min',
    'Fwd Pkt Len Std': 'Fwd Packet Length Std',
    'Fwd Pkts/b Avg': 'Fwd Avg Packets/Bulk',
    'Fwd Pkts/s': 'Fwd Packets/s',
    'Fwd Seg Size Avg': 'Avg Fwd Segment Size',
    'Fwd Seg Size Min': 'min_seg_size_forward',
    'Fwd URG Flags': 'Fwd URG Flags',
    'Idle Max': 'Idle Max',
    'Idle Mean': 'Idle Mean',
    'Idle Min': 'Idle Min',
    'Idle Std': 'Idle Std',
    'Init Bwd Win Byts': 'Init_Win_bytes_backward',
    'Init Fwd Win Byts': 'Init_Win_bytes_forward',
    'PSH Flag Cnt': 'PSH Flag Count',
    'Pkt Len Max': 'Max Packet Length',
    'Pkt Len Mean': 'Packet Length Mean',
    'Pkt Len Min': 'Min Packet Length',
    'Pkt Len Std': 'Packet Length Std',
    'Pkt Len Var': 'Packet Length Variance',
    'Pkt Size Avg': 'Average Packet Size',
    'RST Flag Cnt': 'RST Flag Count',
    'SYN Flag Cnt': 'SYN Flag Count',
    'Subflow Bwd Byts': 'Subflow Bwd Bytes',
    'Subflow Bwd Pkts': 'Subflow Bwd Packets',
    'Subflow Fwd Byts': 'Subflow Fwd Bytes',
    'Subflow Fwd Pkts': 'Subflow Fwd Packets',
    'Tot Bwd Pkts': 'Total Backward Packets',
    'Tot Fwd Pkts': 'Total Fwd Packets',
    'TotLen Bwd Pkts': 'Total Length of Bwd Packets',
    'TotLen Fwd Pkts': 'Total Length of Fwd Packets',
    'URG Flag Cnt': 'URG Flag Count'
}

try:
    expected_features = scaler.feature_names_in_
    print(f"\nModel expects {len(expected_features)} features.")
except AttributeError:
    print("Error: Scaler object does not contain feature names ('feature_names_in_').")
    print("You will need to manually define the 'expected_features' list based on your training data.")
    exit()
except Exception as e:
    print(f"Error retrieving expected features from scaler: {e}")
    exit()

actual_columns_needed = list(column_mapping.keys())

# Check if all needed actual columns exist in the loaded dataframe
missing_actual_cols = set(actual_columns_needed) - set(new_df.columns)
if missing_actual_cols:
    print(f"Error: The loaded CSV is missing columns needed for renaming: {missing_actual_cols}")
    exit()

# Select only the columns we need from the new data
df_to_rename = new_df[actual_columns_needed].copy()

# --- Preprocessing (Using Loaded Objects & Renaming) ---

# Rename the columns to match what the model expects
df_renamed = df_to_rename.rename(columns=column_mapping)
print("\nColumns renamed.")

# Special case. May not be needed
if 'Fwd Header Length.1' in expected_features and 'Fwd Header Length' in df_renamed.columns:
    print("Creating missing 'Fwd Header Length.1' column by duplicating 'Fwd Header Length'.")
    df_renamed['Fwd Header Length.1'] = df_renamed['Fwd Header Length']

# Ensure columns are in the exact order expected by the scaler
# Reindex the DataFrame using the expected feature list
try:
    df_processed = df_renamed[expected_features]
    print("Columns reordered to match scaler expectations.")
except KeyError as e:
     print(f"Error: Failed to reindex columns. Missing column: {e}")
     print("This suggests a mismatch between 'expected_features' and the columns after renaming.")
     exit()

if df_processed.isnull().values.any():
    print("Warning: NaN values found before scaling. Filling with 0 for prediction.")
    df_processed.fillna(0, inplace=True)

try:
    new_data_scaled = scaler.transform(df_processed)
    print("Scaling applied successfully.")
except ValueError as e:
     print(f"Error applying scaler: {e}")
     print("This often means the columns after renaming/reindexing don't match scaler expectations.")
     print(f"Scaler expects columns: {expected_features}")
     print(f"Columns provided to scaler: {df_processed.columns.tolist()}")
     exit()
except Exception as e:
     print(f"Unexpected error during scaling: {e}")
     exit()

# --- Make Predictions ---
print("Making predictions...")
try:
    predictions_numeric = model.predict(new_data_scaled)
    predictions_labels = label_encoder.inverse_transform(predictions_numeric)
    print("Predictions generated successfully.")
except Exception as e:
    print(f"Error during prediction: {e}")
    exit()

# --- Display Results ---
print("\n--- Prediction Results ---")

id_cols = ['Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Destination Port', 'Protocol', 'Timestamp']
id_cols_present = [col for col in id_cols if col in new_df.columns]

results_df = new_df[id_cols_present].copy()
results_df['Predicted_Label_Numeric'] = predictions_numeric
results_df['Predicted_Label'] = predictions_labels

print("\nPrediction Counts:")
print(results_df['Predicted_Label'].value_counts())

print("\nSample Predictions:")
print(results_df.head(3))